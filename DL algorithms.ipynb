{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "8eQ5-0P4ZTws",
        "Hb4nPJQNZYMv",
        "UELbuf7uZlH8",
        "0iI5Tc5qZvMB",
        "Zw0xZ_zjcLAc",
        "ya6xk4NVayse",
        "AQkQ9S9ycBYs",
        "oBbslJo8iRiF",
        "hysSydVEcemF",
        "I044R7llcpgw",
        "ajT2tJfOcsNT",
        "FsWt4XeNeAps",
        "RU8yT98ZeSZq",
        "kYY33OSmfLtP",
        "9inbt4UWfTgj",
        "S9dmJMzIfWwh",
        "Rz6b-mPyf6i6",
        "MBVjS6P7gbFb",
        "Y8la6zsohNhN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IALeMans/Fashion_MNIST_Classification/blob/master/DL%C2%A0algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eQ5-0P4ZTws",
        "colab_type": "text"
      },
      "source": [
        "# Types of Deep Learning Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXgBN7ZQagms",
        "colab_type": "text"
      },
      "source": [
        "toujours le meme objectif : realiser des prédictions type regression (prédire la valeur d'une variable continue), ou de type classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb4nPJQNZYMv",
        "colab_type": "text"
      },
      "source": [
        "## artificial neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oey0Snv9Zb9P",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://www.oreilly.com/library/view/deep-learning/9781491924570/assets/dpln_0201.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UELbuf7uZlH8",
        "colab_type": "text"
      },
      "source": [
        "## recurrent neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8h5ufwRZthE",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://www.oreilly.com/library/view/deep-learning/9781491924570/assets/dpln_0423.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iI5Tc5qZvMB",
        "colab_type": "text"
      },
      "source": [
        "## convolutionnal network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKuq4SduabkK",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://www.oreilly.com/library/view/deep-learning/9781491924570/assets/dpln_0407.png)\n",
        "\n",
        "![Texte alternatif…](https://www.oreilly.com/library/view/deep-learning/9781491924570/assets/dpln_0409.png)\n",
        "\n",
        "![Texte alternatif…](https://www.oreilly.com/library/view/deep-learning/9781491924570/assets/dpln_0411.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw0xZ_zjcLAc",
        "colab_type": "text"
      },
      "source": [
        "## deconvolutionnal networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU_xLN2ycOIX",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](http://www.asimovinstitute.org/wp-content/uploads/2016/09/dn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya6xk4NVayse",
        "colab_type": "text"
      },
      "source": [
        "## autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ine2Nxdb1dv",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](http://www.asimovinstitute.org/wp-content/uploads/2016/09/ae.png)\n",
        "\n",
        "Denoising autoencoder\n",
        "\n",
        "![Texte alternatif…](http://www.asimovinstitute.org/wp-content/uploads/2016/09/dae.png)\n",
        "\n",
        "Sequence-to-sequence models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQkQ9S9ycBYs",
        "colab_type": "text"
      },
      "source": [
        "## generative adversarial networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QpdmCKscdHh",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](http://www.asimovinstitute.org/wp-content/uploads/2016/09/gan.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBbslJo8iRiF",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_axqYjx7iboe",
        "colab_type": "text"
      },
      "source": [
        " word2vec is a group of shallow two-layer models that are used for producing word embeddings. Presented in Efficient Estimation of Word Representations in Vector Space, word2vec takes a large corpus of text as its input and produces a vector space [13]. Every word in the corpus obtains the corresponding vector in this space. The distinctive feature is that words from common contexts in the corpus are located close to one another in the vector space.\n",
        " \n",
        " **Continuous Bag of Words**\n",
        " \n",
        " ![Texte alternatif…](https://www.researchgate.net/profile/Fabio_Massimo_Zanzotto/publication/313247648/figure/fig1/AS:457528493514753@1486094701804/word2vec-CBOW-model.png)\n",
        " \n",
        " **Skip Gram**\n",
        " \n",
        " ![Texte alternatif…](https://www.researchgate.net/profile/Haim_Dubossarsky/publication/319764517/figure/fig1/AS:538859520118785@1505485529904/A-WORD2VEC-SKIP-GRAM-ARCHITECTURE-GIVEN-A-WORD-WT-THE-MODEL-PREDICTS-THE-WORDS.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hysSydVEcemF",
        "colab_type": "text"
      },
      "source": [
        "# Techniques for Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I044R7llcpgw",
        "colab_type": "text"
      },
      "source": [
        "## backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh7mwg5RdCso",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://theclevermachine.files.wordpress.com/2014/09/fprop_bprop5.png?w=600&h=1085)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajT2tJfOcsNT",
        "colab_type": "text"
      },
      "source": [
        "## fonctions d'activation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "285HMrRkdrfV",
        "colab_type": "text"
      },
      "source": [
        "couches cachées\n",
        "\n",
        "![Texte alternatif…](https://knet.readthedocs.io/en/latest/_images/actf.png)\n",
        "\n",
        "couche de sortie\n",
        "\n",
        "![Texte alternatif…](https://i.stack.imgur.com/0rewJ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsWt4XeNeAps",
        "colab_type": "text"
      },
      "source": [
        "## mini batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3UoDKehe4Jx",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://www.bogotobogo.com/python/scikit-learn/images/Batch-vs-Stochastic-Gradient-Descent/mini-batch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU8yT98ZeSZq",
        "colab_type": "text"
      },
      "source": [
        "## stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQANbudkeVx_",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://www.bogotobogo.com/python/scikit-learn/images/Batch-vs-Stochastic-Gradient-Descent/stochastic-vs-batch-gradient-descent.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYY33OSmfLtP",
        "colab_type": "text"
      },
      "source": [
        "## dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_pjPJvkfOC5",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/800/1*PghKZ1K2Lepg01EGfbtKoQ.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9inbt4UWfTgj",
        "colab_type": "text"
      },
      "source": [
        "## max pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2grbMqJ0fVbq",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/600/1*mAb72pBCgfSG707fgDoxgA.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9dmJMzIfWwh",
        "colab_type": "text"
      },
      "source": [
        "## batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN3ScsQNgMe6",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/1600/1*VTNB7oSbyaxtIpZ3kXdH4A.png)\n",
        "\n",
        "Why do we use batch normalization?\n",
        "\n",
        "We normalize the input layer by adjusting and scaling the activations. For example, when we have features from 0 to 1 and some from 1 to 1000, we should normalize them to speed up learning. If the input layer is benefiting from it, why not do the same thing also for the values in the hidden layers, that are changing all the time, and get 10 times or more improvement in the training speed.\n",
        "\n",
        "Batch normalization reduces the amount by what the hidden unit values shift around (covariance shift). To explain covariance shift, let’s have a deep network on cat detection. We train our data on only black cats’ images. So, if we now try to apply this network to data with colored cats, it is obvious; we’re not going to do well. The training set and the prediction set are both cats’ images but they differ a little bit. In other words, if an algorithm learned some X to Y mapping, and if the distribution of X changes, then we might need to retrain the learning algorithm by trying to align the distribution of X with the distribution of Y. ( Deeplearning.ai: Why Does Batch Norm Work? (C2W3L06))\n",
        "\n",
        "Also, batch normalization allows each layer of a network to learn by itself a little bit more independently of other layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz6b-mPyf6i6",
        "colab_type": "text"
      },
      "source": [
        "## gradient clipping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGLdBSh-f8ft",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://qph.fs.quoracdn.net/main-qimg-d0f12f2e19359820bfa909467a928141)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBVjS6P7gbFb",
        "colab_type": "text"
      },
      "source": [
        "## transfert learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCk3WLB9gdoU",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/800/1*ovNMgv2yulRn6mnpzOSkUg.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8la6zsohNhN",
        "colab_type": "text"
      },
      "source": [
        "# Reinforcement learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR--tFmwhSMB",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://skymind.ai/images/wiki/conv_agent.png)"
      ]
    }
  ]
}